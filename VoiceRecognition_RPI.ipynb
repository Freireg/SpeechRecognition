{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VoiceRecognition_RPI.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXk4a6y4hgf5GnXa8ef/4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Freireg/SpeechRecognition/blob/main/VoiceRecognition_RPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UIQc33OsmSr",
        "outputId": "8a36d0e5-e6b9-488f-b05e-08a9e68bc64c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.7/dist-packages (0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "AxlAA6Oxn6xq"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isdir, join\n",
        "import librosa\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import python_speech_features\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.mount('Machine_Learning_Dataset')\n",
        "dataset_path = '/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets'\n",
        "\n",
        "for name in listdir(dataset_path):\n",
        "  if isdir(join(dataset_path, name)):\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9ZPKVT3tzfy",
        "outputId": "085174b5-7405-41b8-de05-2fee6aacc548"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "follow\n",
            "_background_noise_\n",
            "backward\n",
            "bird\n",
            "cat\n",
            "dog\n",
            "down\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an all targets list\n",
        "all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
        "all_targets.remove('_background_noise_')\n",
        "print(all_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i78oyADcxRwG",
        "outputId": "7ee3ee81-f33b-4f7a-aa6b-10492d95e21a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['follow', 'backward', 'bird', 'cat', 'dog', 'down']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "target_list = all_targets\n",
        "feature_sets_file = '/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/all_targets_mfcc_sets.npz'\n",
        "perc_keep_samples = 1.0 # 1.0 is keep all samples\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "sample_rate = 8000\n",
        "num_mfcc = 16\n",
        "len_mfcc = 16"
      ],
      "metadata": {
        "id": "_SkcV5TooPfW"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of filenames along with ground truth vector (y)\n",
        "filenames = []\n",
        "y = []\n",
        "for index, target in enumerate(target_list):\n",
        "    print(join(dataset_path, target))\n",
        "    filenames.append(listdir(join(dataset_path, target)))\n",
        "    y.append(np.ones(len(filenames[index])) * index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRkdLMVgxZOR",
        "outputId": "41f3bf3a-5574-486e-8955-c79666295925"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/follow\n",
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/backward\n",
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/bird\n",
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/cat\n",
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/dog\n",
            "/content/Machine_Learning_Dataset/MyDrive/Machine_Learning_Dataset/Datasets/down\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check ground truth Y vector\n",
        "print(y)\n",
        "for item in y:\n",
        "    print(len(item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI1XO19AxbLN",
        "outputId": "6485a076-6888-4f94-e909-572eced36ff2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0., 0., 0., ..., 0., 0., 0.]), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1.]), array([2., 2., 2., ..., 2., 2., 2.]), array([3., 3., 3., ..., 3., 3., 3.]), array([4., 4., 4., ..., 4., 4., 4.]), array([5., 5., 5., ..., 5., 5., 5.])]\n",
            "1579\n",
            "297\n",
            "2064\n",
            "2031\n",
            "2128\n",
            "1870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten filename and y vectors\n",
        "filenames = [item for sublist in filenames for item in sublist]\n",
        "y = [item for sublist in y for item in sublist]"
      ],
      "metadata": {
        "id": "MOLM0eO3xdNR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associate filenames with true output and shuffle\n",
        "filenames_y = list(zip(filenames, y))\n",
        "random.shuffle(filenames_y)\n",
        "filenames, y = zip(*filenames_y)"
      ],
      "metadata": {
        "id": "xSepYAFTxe8g"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only keep the specified number of samples (shorter extraction/training)\n",
        "print(len(filenames))\n",
        "filenames = filenames[:int(len(filenames) * perc_keep_samples)]\n",
        "print(len(filenames))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyA7DUHRxgcD",
        "outputId": "40d75527-c490-4d96-f542-608cc0dea930"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9969\n",
            "9969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate validation and test set sizes\n",
        "val_set_size = int(len(filenames) * val_ratio)\n",
        "test_set_size = int(len(filenames) * test_ratio)"
      ],
      "metadata": {
        "id": "RZ_MCliuxh47"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Break dataset apart into train, validation, and test sets\n",
        "filenames_val = filenames[:val_set_size]\n",
        "filenames_test = filenames[val_set_size:(val_set_size + test_set_size)]\n",
        "filenames_train = filenames[(val_set_size + test_set_size):]"
      ],
      "metadata": {
        "id": "G75TYC0mxjWJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Break y apart into train, validation, and test sets\n",
        "y_orig_val = y[:val_set_size]\n",
        "y_orig_test = y[val_set_size:(val_set_size + test_set_size)]\n",
        "y_orig_train = y[(val_set_size + test_set_size):]"
      ],
      "metadata": {
        "id": "0hn4swxKxkxY"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Create MFCC from given path\n",
        "def calc_mfcc(path):\n",
        "    \n",
        "    # Load wavefile\n",
        "    signal, fs = librosa.load(path, sr=sample_rate)\n",
        "    \n",
        "    # Create MFCCs from sound clip\n",
        "    mfccs = python_speech_features.base.mfcc(signal, \n",
        "                                            samplerate=fs,\n",
        "                                            winlen=0.256,\n",
        "                                            winstep=0.050,\n",
        "                                            numcep=num_mfcc,\n",
        "                                            nfilt=26,\n",
        "                                            nfft=2048,\n",
        "                                            preemph=0.0,\n",
        "                                            ceplifter=0,\n",
        "                                            appendEnergy=False,\n",
        "                                            winfunc=np.hanning)\n",
        "    return mfccs.transpose()"
      ],
      "metadata": {
        "id": "Tlz8sKIqxmc2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Construct test set by computing MFCC of each WAV file\n",
        "prob_cnt = 0\n",
        "x_test = []\n",
        "y_test = []\n",
        "for index, filename in enumerate(filenames_train):\n",
        "    \n",
        "    # Stop after 500\n",
        "    if index >= 500:\n",
        "        break\n",
        "    \n",
        "    # Create path from given filename and target item\n",
        "    path = join(dataset_path, target_list[int(y_orig_train[index])], \n",
        "                filename)\n",
        "    \n",
        "    # Create MFCCs\n",
        "    mfccs = calc_mfcc(path)\n",
        "    \n",
        "    if mfccs.shape[1] == len_mfcc:\n",
        "        x_test.append(mfccs)\n",
        "        y_test.append(y_orig_train[index])\n",
        "    else:\n",
        "        print('Dropped:', index, mfccs.shape)\n",
        "        prob_cnt += 1\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1QM0R0Lxq_h",
        "outputId": "0e546b40-9bfd-412d-f7c6-d1cdbb66b562"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped: 6 (16, 11)\n",
            "Dropped: 11 (16, 9)\n",
            "Dropped: 21 (16, 13)\n",
            "Dropped: 30 (16, 9)\n",
            "Dropped: 42 (16, 10)\n",
            "Dropped: 50 (16, 7)\n",
            "Dropped: 68 (16, 14)\n",
            "Dropped: 82 (16, 12)\n",
            "Dropped: 90 (16, 13)\n",
            "Dropped: 102 (16, 11)\n",
            "Dropped: 108 (16, 11)\n",
            "Dropped: 127 (16, 15)\n",
            "Dropped: 129 (16, 10)\n",
            "Dropped: 140 (16, 14)\n",
            "Dropped: 165 (16, 13)\n",
            "Dropped: 171 (16, 14)\n",
            "Dropped: 178 (16, 8)\n",
            "Dropped: 183 (16, 11)\n",
            "Dropped: 195 (16, 13)\n",
            "Dropped: 199 (16, 11)\n",
            "Dropped: 203 (16, 13)\n",
            "Dropped: 209 (16, 13)\n",
            "Dropped: 213 (16, 9)\n",
            "Dropped: 223 (16, 14)\n",
            "Dropped: 224 (16, 15)\n",
            "Dropped: 230 (16, 15)\n",
            "Dropped: 241 (16, 11)\n",
            "Dropped: 279 (16, 15)\n",
            "Dropped: 287 (16, 14)\n",
            "Dropped: 289 (16, 12)\n",
            "Dropped: 303 (16, 13)\n",
            "Dropped: 329 (16, 12)\n",
            "Dropped: 346 (16, 12)\n",
            "Dropped: 352 (16, 15)\n",
            "Dropped: 366 (16, 12)\n",
            "Dropped: 375 (16, 12)\n",
            "Dropped: 377 (16, 11)\n",
            "Dropped: 380 (16, 15)\n",
            "Dropped: 383 (16, 13)\n",
            "Dropped: 384 (16, 8)\n",
            "Dropped: 386 (16, 14)\n",
            "Dropped: 391 (16, 10)\n",
            "Dropped: 395 (16, 11)\n",
            "Dropped: 398 (16, 7)\n",
            "Dropped: 419 (16, 10)\n",
            "Dropped: 438 (16, 11)\n",
            "Dropped: 485 (16, 14)\n",
            "Dropped: 497 (16, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('% of problematic samples:', prob_cnt / 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49y4sx6Qxuz8",
        "outputId": "3365eb93-5f9f-43f0-ee95-e7023f5f6308"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of problematic samples: 0.096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Test shorter MFCC\n",
        "#!pip install playsound\n",
        "#from playsound import playsound\n",
        "\n",
        "#idx = 13\n",
        "\n",
        "# Create path from given filename and target item\n",
        "#path = join(dataset_path, target_list[int(y_orig_train[idx])], \n",
        "#            filenames_train[idx])\n",
        "\n",
        "# Create MFCCs\n",
        "#mfccs = calc_mfcc(path)\n",
        "#print(\"MFCCs:\", mfccs)\n",
        "\n",
        "# Plot MFCC\n",
        "#fig = plt.figure()\n",
        "#plt.imshow(mfccs, cmap='inferno', origin='lower')\n",
        "\n",
        "# TEST: Play problem sounds\n",
        "#print(target_list[int(y_orig_train[idx])])\n",
        "#playsound(path)"
      ],
      "metadata": {
        "id": "2o3GmM2cxvkv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Create MFCCs, keeping only ones of desired length\n",
        "def extract_features(in_files, in_y):\n",
        "    prob_cnt = 0\n",
        "    out_x = []\n",
        "    out_y = []\n",
        "        \n",
        "    for index, filename in enumerate(in_files):\n",
        "    \n",
        "        # Create path from given filename and target item\n",
        "        path = join(dataset_path, target_list[int(in_y[index])], \n",
        "                    filename)\n",
        "        \n",
        "        # Check to make sure we're reading a .wav file\n",
        "        if not path.endswith('.wav'):\n",
        "            continue\n",
        "\n",
        "        # Create MFCCs\n",
        "        mfccs = calc_mfcc(path)\n",
        "\n",
        "        # Only keep MFCCs with given length\n",
        "        if mfccs.shape[1] == len_mfcc:\n",
        "            out_x.append(mfccs)\n",
        "            out_y.append(in_y[index])\n",
        "        else:\n",
        "            print('Dropped:', index, mfccs.shape)\n",
        "            prob_cnt += 1\n",
        "            \n",
        "    return out_x, out_y, prob_cnt"
      ],
      "metadata": {
        "id": "599ozyJRxzII"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train, validation, and test sets\n",
        "x_train, y_train, prob = extract_features(filenames_train, \n",
        "                                          y_orig_train)\n",
        "print('Removed percentage:', prob / len(y_orig_train))\n",
        "x_val, y_val, prob = extract_features(filenames_val, y_orig_val)\n",
        "print('Removed percentage:', prob / len(y_orig_val))\n",
        "x_test, y_test, prob = extract_features(filenames_test, y_orig_test)\n",
        "print('Removed percentage:', prob / len(y_orig_test))"
      ],
      "metadata": {
        "id": "-HOu5CVux0th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save features and truth vector (y) sets to disk\n",
        "np.savez(feature_sets_file, \n",
        "         x_train=x_train, \n",
        "         y_train=y_train, \n",
        "         x_val=x_val, \n",
        "         y_val=y_val, \n",
        "         x_test=x_test, \n",
        "         y_test=y_test)"
      ],
      "metadata": {
        "id": "S9VmpR0lx1zV"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST: Load features\n",
        "feature_sets = np.load(feature_sets_file)\n",
        "feature_sets.files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7uFsHwAx2zU",
        "outputId": "87880793-c67d-47df-9fd7-97c0b99535d6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature_sets['x_train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnuPdkCUx3yv",
        "outputId": "78effc78-6fb1-4f15-e16f-1f0d6d5262b7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7107"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_sets['y_val'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWzAi4eRx5XJ",
        "outputId": "dc2e10e1-3ca3-4c29-df02-0dc5a424142c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 0. 2. 2. 4. 4. 5. 0. 4. 3. 0. 1. 5. 5. 4. 3. 5. 2. 0. 4. 1. 4. 5. 3.\n",
            " 4. 3. 0. 4. 2. 2. 2. 4. 3. 5. 0. 3. 2. 5. 2. 5. 2. 3. 0. 2. 5. 3. 5. 0.\n",
            " 5. 5. 4. 0. 3. 2. 0. 5. 4. 3. 0. 5. 4. 0. 1. 5. 4. 0. 2. 0. 4. 3. 0. 4.\n",
            " 0. 4. 4. 2. 0. 3. 0. 0. 2. 5. 2. 3. 4. 5. 3. 2. 4. 5. 2. 4. 0. 2. 4. 0.\n",
            " 5. 5. 2. 5. 0. 5. 4. 2. 5. 5. 0. 5. 4. 5. 1. 4. 2. 5. 5. 4. 4. 4. 0. 4.\n",
            " 3. 5. 5. 3. 2. 3. 3. 5. 4. 0. 3. 0. 5. 0. 4. 5. 2. 0. 5. 5. 0. 4. 5. 5.\n",
            " 3. 0. 5. 2. 2. 0. 0. 0. 0. 2. 4. 5. 2. 5. 2. 2. 4. 0. 3. 3. 4. 5. 2. 2.\n",
            " 2. 3. 0. 3. 0. 2. 5. 2. 5. 4. 0. 3. 0. 4. 0. 4. 3. 2. 2. 3. 3. 5. 5. 4.\n",
            " 3. 5. 3. 4. 3. 2. 3. 1. 4. 0. 3. 0. 4. 4. 3. 5. 0. 2. 5. 0. 0. 4. 0. 0.\n",
            " 5. 5. 4. 4. 3. 0. 2. 0. 2. 5. 3. 2. 2. 4. 1. 4. 0. 4. 5. 5. 3. 3. 4. 5.\n",
            " 4. 2. 4. 3. 0. 0. 0. 3. 4. 3. 1. 4. 0. 3. 5. 2. 4. 5. 4. 0. 2. 4. 4. 5.\n",
            " 4. 4. 5. 3. 5. 2. 2. 4. 3. 0. 0. 3. 3. 3. 3. 2. 4. 3. 1. 3. 4. 3. 4. 3.\n",
            " 0. 0. 0. 2. 4. 2. 3. 1. 4. 0. 2. 0. 4. 4. 5. 3. 5. 5. 2. 0. 4. 2. 2. 1.\n",
            " 2. 4. 5. 3. 4. 3. 0. 4. 5. 2. 5. 5. 4. 3. 4. 2. 0. 4. 4. 2. 3. 5. 2. 4.\n",
            " 3. 0. 3. 2. 4. 2. 5. 5. 4. 4. 5. 5. 5. 4. 5. 0. 2. 3. 5. 0. 0. 2. 0. 0.\n",
            " 3. 5. 1. 4. 0. 0. 3. 4. 3. 0. 4. 5. 4. 4. 1. 5. 0. 0. 2. 0. 5. 3. 4. 4.\n",
            " 5. 2. 3. 3. 5. 5. 3. 4. 3. 5. 3. 0. 0. 5. 5. 3. 4. 3. 3. 2. 4. 3. 3. 5.\n",
            " 3. 4. 0. 5. 2. 3. 3. 3. 2. 5. 2. 5. 1. 3. 4. 3. 2. 0. 3. 0. 3. 5. 3. 3.\n",
            " 3. 2. 3. 0. 3. 0. 4. 2. 4. 3. 2. 5. 2. 3. 3. 4. 5. 3. 0. 0. 4. 0. 2. 2.\n",
            " 4. 3. 0. 4. 5. 5. 1. 5. 4. 0. 5. 3. 3. 3. 3. 3. 4. 0. 5. 3. 2. 1. 0. 5.\n",
            " 2. 4. 5. 2. 5. 2. 4. 2. 4. 3. 0. 2. 2. 2. 0. 4. 4. 3. 2. 3. 4. 4. 3. 3.\n",
            " 5. 3. 2. 3. 3. 0. 3. 5. 4. 4. 4. 0. 2. 5. 0. 0. 2. 4. 0. 3. 0. 0. 0. 2.\n",
            " 1. 3. 5. 2. 2. 3. 4. 2. 2. 5. 4. 3. 1. 2. 0. 2. 0. 4. 4. 5. 4. 5. 3. 2.\n",
            " 4. 3. 4. 5. 0. 4. 3. 0. 2. 4. 3. 3. 5. 5. 4. 3. 2. 2. 3. 4. 2. 4. 5. 2.\n",
            " 3. 2. 2. 4. 3. 5. 2. 3. 5. 3. 2. 5. 1. 2. 5. 5. 0. 5. 4. 4. 2. 0. 2. 0.\n",
            " 4. 4. 5. 5. 0. 3. 2. 0. 0. 2. 1. 1. 4. 2. 4. 4. 4. 0. 5. 5. 3. 3. 2. 5.\n",
            " 2. 4. 0. 3. 0. 3. 2. 5. 4. 2. 0. 0. 4. 3. 3. 4. 4. 3. 0. 2. 0. 3. 4. 3.\n",
            " 2. 0. 0. 1. 1. 5. 5. 2. 2. 0. 3. 0. 0. 5. 5. 4. 3. 3. 5. 5. 3. 5. 3. 2.\n",
            " 0. 1. 5. 2. 0. 4. 4. 2. 2. 0. 4. 4. 0. 4. 2. 5. 3. 5. 3. 5. 4. 5. 0. 2.\n",
            " 0. 0. 4. 3. 3. 3. 3. 5. 5. 5. 2. 4. 5. 4. 0. 1. 4. 2. 3. 5. 2. 2. 5. 5.\n",
            " 4. 4. 5. 2. 3. 4. 3. 2. 5. 3. 2. 0. 2. 3. 4. 0. 4. 5. 4. 3. 5. 4. 3. 0.\n",
            " 4. 5. 2. 4. 5. 4. 4. 2. 2. 5. 0. 4. 0. 5. 4. 0. 3. 4. 4. 3. 4. 2. 4. 4.\n",
            " 4. 0. 5. 5. 2. 3. 5. 3. 5. 2. 3. 3. 3. 4. 0. 0. 5. 4. 5. 0. 4. 4. 4. 2.\n",
            " 1. 4. 4. 3. 3. 5. 5. 2. 1. 4. 2. 0. 2. 1. 3. 3. 3. 4. 4. 5. 0. 5. 4. 4.\n",
            " 0. 3. 4. 5. 4. 5. 4. 5. 3. 2. 4. 2. 5. 4. 2. 0. 4. 0. 3. 4. 2. 0. 2. 2.\n",
            " 0. 3. 5. 5. 4. 3. 5. 2. 5. 4. 4. 0. 2. 0. 4. 3. 3. 3. 2. 1. 0. 2. 4. 4.\n",
            " 3. 2. 5. 2. 2. 5. 2. 4. 5. 2. 0. 0. 5. 4. 3. 2. 2. 2. 4. 5. 0. 2. 4. 3.\n",
            " 4. 5. 5. 2. 4. 4. 0. 2. 3. 0. 0. 1. 3.]\n"
          ]
        }
      ]
    }
  ]
}